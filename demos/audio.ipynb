{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from uuid import UUID, uuid4\n",
    "from typing import List, Optional, Dict, Union, Tuple\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "import random\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Enums for audio properties\n",
    "class AudioFormat(str, Enum):\n",
    "    WAV = \"wav\"\n",
    "    MP3 = \"mp3\"\n",
    "    FLAC = \"flac\"\n",
    "    OGG = \"ogg\"\n",
    "    AAC = \"aac\"\n",
    "\n",
    "class LanguageCode(str, Enum):\n",
    "    ENGLISH = \"en\"\n",
    "    FRENCH = \"fr\"\n",
    "    SPANISH = \"es\"\n",
    "    CHINESE = \"zh\"\n",
    "    JAPANESE = \"ja\"\n",
    "    GERMAN = \"de\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "# Main audio model\n",
    "class Audio(BaseModel):\n",
    "    id: UUID = Field(default_factory=uuid4)\n",
    "    file_path: str\n",
    "    format: AudioFormat\n",
    "    sample_rate: int = 44100  # Hz\n",
    "    bit_depth: int = 16  # bits\n",
    "    channels: int = 2  # 1=mono, 2=stereo\n",
    "    duration: float  # Duration in seconds\n",
    "    detected_language: Optional[LanguageCode] = None\n",
    "    transcript: Optional[str] = None\n",
    "    \n",
    "    def model_post_init(self, __context):\n",
    "        # Auto-save after initialization\n",
    "        save_audio_metadata(self)\n",
    "\n",
    "# Audio segment for time-based operations\n",
    "class AudioSegment(BaseModel):\n",
    "    id: UUID = Field(default_factory=uuid4)\n",
    "    audio_id: UUID  # Reference to parent audio\n",
    "    start_time: float  # Start time in seconds\n",
    "    end_time: float  # End time in seconds\n",
    "    \n",
    "    @field_validator('end_time')\n",
    "    def validate_time_range(cls, v, values):\n",
    "        start = values.data.get('start_time')\n",
    "        if start is not None and v <= start:\n",
    "            raise ValueError('end_time must be greater than start_time')\n",
    "        return v\n",
    "    \n",
    "    def model_post_init(self, __context):\n",
    "        # Auto-save after initialization\n",
    "        save_audio_metadata(self)\n",
    "\n",
    "    @property\n",
    "    def duration(self) -> float:\n",
    "        return self.end_time - self.start_time\n",
    "\n",
    "# Audio processing functions\n",
    "def noise_reduction(audio_id: UUID, strength: float = 0.5) -> UUID:\n",
    "    \"\"\"\n",
    "    Reduce noise in audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to process\n",
    "    - strength: Noise reduction strength (0.0-1.0)\n",
    "    \n",
    "    Returns:\n",
    "    - UUID of the processed audio\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # Create a new audio object for the result\n",
    "    processed_audio = audio.model_copy()\n",
    "    processed_audio.id = uuid4()\n",
    "    processed_audio.file_path = f\"processed_{processed_audio.id}.{audio.format.value}\"\n",
    "    \n",
    "    # In a real implementation, this would call audio processing libraries\n",
    "    print(f\"Applying noise reduction with strength {strength} to {audio.file_path}\")\n",
    "    \n",
    "    # Save the new metadata\n",
    "    save_audio_metadata(processed_audio)\n",
    "    return processed_audio.id\n",
    "\n",
    "def text_to_speech(text: str, voice: str = \"default\", language: LanguageCode = LanguageCode.ENGLISH) -> UUID:\n",
    "    \"\"\"\n",
    "    Convert text to speech.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: Text to convert to speech\n",
    "    - voice: Voice identifier\n",
    "    - language: Language code\n",
    "    \n",
    "    Returns:\n",
    "    - UUID of the generated audio\n",
    "    \"\"\"\n",
    "    # Create new audio for TTS result\n",
    "    audio = Audio(\n",
    "        file_path=f\"tts_{uuid4()}.wav\",\n",
    "        format=AudioFormat.WAV,\n",
    "        duration=len(text) * 0.07,  # Estimate duration based on text length\n",
    "        detected_language=language,\n",
    "        transcript=text\n",
    "    )\n",
    "    \n",
    "    # In a real implementation, this would call a TTS service\n",
    "    print(f\"Generating speech for text: '{text}' using voice '{voice}' in {language}\")\n",
    "    \n",
    "    save_audio_metadata(audio)\n",
    "    return audio.id\n",
    "\n",
    "def detect_language(audio_id: UUID) -> LanguageCode:\n",
    "    \"\"\"\n",
    "    Detect spoken language in audio.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to analyze\n",
    "    \n",
    "    Returns:\n",
    "    - Detected language code\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # In a real implementation, this would use a speech recognition service\n",
    "    detected = random.choice(list(LanguageCode))\n",
    "    \n",
    "    # Update audio with detected language\n",
    "    audio.detected_language = detected\n",
    "    save_audio_metadata(audio)\n",
    "    \n",
    "    return detected\n",
    "\n",
    "def transcribe_audio(audio_id: UUID, language: Optional[LanguageCode] = None) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe speech in audio to text.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to transcribe\n",
    "    - language: Language code (if known)\n",
    "    \n",
    "    Returns:\n",
    "    - Transcribed text\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # Use provided language or detected language\n",
    "    lang = language or audio.detected_language or LanguageCode.ENGLISH\n",
    "    \n",
    "    # In a real implementation, this would use a speech recognition service\n",
    "    sample_texts = {\n",
    "        LanguageCode.ENGLISH: \"This is a sample transcription.\",\n",
    "        LanguageCode.FRENCH: \"Ceci est une transcription exemple.\",\n",
    "        LanguageCode.SPANISH: \"Esta es una transcripción de muestra.\",\n",
    "        LanguageCode.CHINESE: \"这是一个示例转录。\",\n",
    "        LanguageCode.JAPANESE: \"これはサンプル文字起こしです。\",\n",
    "        LanguageCode.GERMAN: \"Dies ist eine Beispieltranskription.\",\n",
    "        LanguageCode.UNKNOWN: \"This is a sample transcription.\"\n",
    "    }\n",
    "    \n",
    "    transcript = sample_texts.get(lang, \"This is a sample transcription.\")\n",
    "    \n",
    "    # Update audio with transcript\n",
    "    audio.transcript = transcript\n",
    "    save_audio_metadata(audio)\n",
    "    \n",
    "    return transcript\n",
    "\n",
    "def split_audio_by_time(audio_id: UUID, timestamps: List[float]) -> List[UUID]:\n",
    "    \"\"\"\n",
    "    Split audio at specified timestamps.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to split\n",
    "    - timestamps: List of timestamps in seconds where to split\n",
    "    \n",
    "    Returns:\n",
    "    - List of UUIDs for the resulting AudioSegment objects\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # Sort timestamps and add start/end if needed\n",
    "    all_points = sorted([0] + timestamps + [audio.duration])\n",
    "    \n",
    "    segments = []\n",
    "    for i in range(len(all_points) - 1):\n",
    "        segment = AudioSegment(\n",
    "            audio_id=audio.id,\n",
    "            start_time=all_points[i],\n",
    "            end_time=all_points[i+1]\n",
    "        )\n",
    "        segments.append(segment)\n",
    "        save_audio_metadata(segment)\n",
    "    \n",
    "    return [segment.id for segment in segments]\n",
    "\n",
    "def split_audio_by_silence(audio_id: UUID, min_silence_duration: float = 0.5, silence_threshold: float = -40) -> List[UUID]:\n",
    "    \"\"\"\n",
    "    Split audio at silent parts.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to split\n",
    "    - min_silence_duration: Minimum silence duration to trigger split (seconds)\n",
    "    - silence_threshold: Volume threshold for silence detection (dB)\n",
    "    \n",
    "    Returns:\n",
    "    - List of UUIDs for the resulting AudioSegment objects\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # In a real implementation, this would analyze the audio waveform\n",
    "    # For this example, we'll generate random splits\n",
    "    num_splits = random.randint(2, 5)\n",
    "    points = sorted([random.uniform(0, audio.duration) for _ in range(num_splits)])\n",
    "    \n",
    "    # Create segments\n",
    "    return split_audio_by_time(audio_id, points)\n",
    "\n",
    "def merge_audio_segments(segment_ids: List[UUID], crossfade: float = 0.0) -> UUID:\n",
    "    \"\"\"\n",
    "    Merge multiple audio segments into a single audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    - segment_ids: List of AudioSegment UUIDs to merge\n",
    "    - crossfade: Crossfade duration between segments (seconds)\n",
    "    \n",
    "    Returns:\n",
    "    - UUID of the resulting audio\n",
    "    \"\"\"\n",
    "    if not segment_ids:\n",
    "        raise ValueError(\"No segments provided for merging\")\n",
    "    \n",
    "    segments = [load_audio_metadata(seg_id) for seg_id in segment_ids]\n",
    "    \n",
    "    # Get parent audio to determine properties\n",
    "    parent_audios = [load_audio_metadata(seg.audio_id) for seg in segments]\n",
    "    \n",
    "    # Use properties from first parent audio\n",
    "    first_parent = parent_audios[0]\n",
    "    \n",
    "    # Calculate total duration\n",
    "    total_duration = sum(seg.duration for seg in segments)\n",
    "    if crossfade > 0 and len(segments) > 1:\n",
    "        total_duration -= crossfade * (len(segments) - 1)\n",
    "    \n",
    "    # Create new audio for merged result\n",
    "    merged_audio = Audio(\n",
    "        file_path=f\"merged_{uuid4()}.{first_parent.format.value}\",\n",
    "        format=first_parent.format,\n",
    "        sample_rate=first_parent.sample_rate,\n",
    "        bit_depth=first_parent.bit_depth,\n",
    "        channels=first_parent.channels,\n",
    "        duration=total_duration\n",
    "    )\n",
    "    \n",
    "    # In a real implementation, this would perform actual audio merging\n",
    "    print(f\"Merging {len(segments)} segments with {crossfade}s crossfade\")\n",
    "    \n",
    "    save_audio_metadata(merged_audio)\n",
    "    return merged_audio.id\n",
    "\n",
    "def apply_effect(audio_id: UUID, effect_type: str, parameters: Dict = None) -> UUID:\n",
    "    \"\"\"\n",
    "    Apply audio effect to the audio.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to process\n",
    "    - effect_type: Type of effect (e.g., \"reverb\", \"eq\", \"compression\")\n",
    "    - parameters: Effect-specific parameters\n",
    "    \n",
    "    Returns:\n",
    "    - UUID of the processed audio\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    parameters = parameters or {}\n",
    "    \n",
    "    # Create a new audio object for the result\n",
    "    processed_audio = audio.model_copy()\n",
    "    processed_audio.id = uuid4()\n",
    "    processed_audio.file_path = f\"{effect_type}_{processed_audio.id}.{audio.format.value}\"\n",
    "    \n",
    "    # In a real implementation, this would apply the actual effect\n",
    "    print(f\"Applying {effect_type} effect with parameters {parameters} to {audio.file_path}\")\n",
    "    \n",
    "    save_audio_metadata(processed_audio)\n",
    "    return processed_audio.id\n",
    "\n",
    "def change_audio_format(audio_id: UUID, target_format: AudioFormat) -> UUID:\n",
    "    \"\"\"\n",
    "    Convert audio to a different format.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to convert\n",
    "    - target_format: Target audio format\n",
    "    \n",
    "    Returns:\n",
    "    - UUID of the converted audio\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # If already in target format, return original\n",
    "    if audio.format == target_format:\n",
    "        return audio.id\n",
    "    \n",
    "    # Create a new audio object for the result\n",
    "    converted_audio = audio.model_copy()\n",
    "    converted_audio.id = uuid4()\n",
    "    converted_audio.format = target_format\n",
    "    \n",
    "    # Update file path with new extension\n",
    "    base_name = Path(audio.file_path).stem\n",
    "    converted_audio.file_path = f\"{base_name}.{target_format.value}\"\n",
    "    \n",
    "    # In a real implementation, this would convert the audio file\n",
    "    print(f\"Converting {audio.file_path} from {audio.format} to {target_format}\")\n",
    "    \n",
    "    save_audio_metadata(converted_audio)\n",
    "    return converted_audio.id\n",
    "\n",
    "def adjust_audio_properties(\n",
    "    audio_id: UUID, \n",
    "    sample_rate: Optional[int] = None,\n",
    "    bit_depth: Optional[int] = None,\n",
    "    channels: Optional[int] = None\n",
    ") -> UUID:\n",
    "    \"\"\"\n",
    "    Adjust audio properties like sample rate, bit depth, or channels.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to adjust\n",
    "    - sample_rate: Target sample rate in Hz\n",
    "    - bit_depth: Target bit depth in bits\n",
    "    - channels: Target number of channels\n",
    "    \n",
    "    Returns:\n",
    "    - UUID of the adjusted audio\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # Create a new audio object for the result\n",
    "    adjusted_audio = audio.model_copy()\n",
    "    adjusted_audio.id = uuid4()\n",
    "    \n",
    "    # Update properties if provided\n",
    "    if sample_rate is not None:\n",
    "        adjusted_audio.sample_rate = sample_rate\n",
    "    if bit_depth is not None:\n",
    "        adjusted_audio.bit_depth = bit_depth\n",
    "    if channels is not None:\n",
    "        adjusted_audio.channels = channels\n",
    "    \n",
    "    adjusted_audio.file_path = f\"adjusted_{adjusted_audio.id}.{audio.format.value}\"\n",
    "    \n",
    "    # In a real implementation, this would adjust the audio properties\n",
    "    print(f\"Adjusting audio properties: sample_rate={sample_rate}, bit_depth={bit_depth}, channels={channels}\")\n",
    "    \n",
    "    save_audio_metadata(adjusted_audio)\n",
    "    return adjusted_audio.id\n",
    "\n",
    "# Storage functions\n",
    "AUDIO_DATA_DIR = \"./audio_data\"\n",
    "\n",
    "def save_audio_metadata(obj: Union[Audio, AudioSegment]):\n",
    "    \"\"\"Save audio metadata to JSON file\"\"\"\n",
    "    # Ensure directory exists\n",
    "    Path(AUDIO_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save to JSON file\n",
    "    file_path = Path(AUDIO_DATA_DIR) / f\"{obj.id}.json\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(obj.model_dump_json())\n",
    "\n",
    "def load_audio_metadata(obj_id: UUID) -> Union[Audio, AudioSegment]:\n",
    "    \"\"\"Load audio metadata from JSON file\"\"\"\n",
    "    file_path = Path(AUDIO_DATA_DIR) / f\"{obj_id}.json\"\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        raise ValueError(f\"No audio data found for ID {obj_id}\")\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Determine type by checking for specific fields\n",
    "    if 'start_time' in data:\n",
    "        return AudioSegment.model_validate(data)\n",
    "    else:\n",
    "        return Audio.model_validate(data)\n",
    "\n",
    "# Example functions to create objects\n",
    "def create_audio_from_file(file_path: str, format: AudioFormat, **kwargs) -> UUID:\n",
    "    \"\"\"Create Audio object from file path\"\"\"\n",
    "    # Get audio properties (in a real implementation, would extract from the file)\n",
    "    props = {\n",
    "        'sample_rate': 44100,\n",
    "        'bit_depth': 16,\n",
    "        'channels': 2,\n",
    "        'duration': 60.0,  # Default 1 minute\n",
    "    }\n",
    "    \n",
    "    # Override with provided kwargs\n",
    "    props.update(kwargs)\n",
    "    \n",
    "    audio = Audio(\n",
    "        file_path=file_path,\n",
    "        format=format,\n",
    "        **props\n",
    "    )\n",
    "    \n",
    "    return audio.id\n",
    "\n",
    "# Higher-level processing functions\n",
    "def enhance_audio(audio_id: UUID) -> UUID:\n",
    "    \"\"\"\n",
    "    Apply a series of enhancements to improve audio quality.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to enhance\n",
    "    \n",
    "    Returns:\n",
    "    - UUID of the enhanced audio\n",
    "    \"\"\"\n",
    "    # Apply noise reduction\n",
    "    reduced_id = noise_reduction(audio_id, strength=0.7)\n",
    "    \n",
    "    # Apply EQ effect\n",
    "    eq_params = {\n",
    "        \"low\": 1.2,\n",
    "        \"mid\": 1.0,\n",
    "        \"high\": 1.1\n",
    "    }\n",
    "    eq_id = apply_effect(reduced_id, \"eq\", eq_params)\n",
    "    \n",
    "    # Apply compression\n",
    "    comp_params = {\n",
    "        \"threshold\": -20,\n",
    "        \"ratio\": 4,\n",
    "        \"attack\": 5,\n",
    "        \"release\": 50\n",
    "    }\n",
    "    compressed_id = apply_effect(eq_id, \"compression\", comp_params)\n",
    "    \n",
    "    return compressed_id\n",
    "\n",
    "def voice_activity_detection(audio_id: UUID) -> List[Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Detect segments with voice activity.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to analyze\n",
    "    \n",
    "    Returns:\n",
    "    - List of (start_time, end_time) tuples for voice segments\n",
    "    \"\"\"\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    # In a real implementation, this would analyze the audio\n",
    "    # For this example, generate random voice segments\n",
    "    segments = []\n",
    "    current_time = 0\n",
    "    \n",
    "    while current_time < audio.duration:\n",
    "        # Random voice segment length\n",
    "        voice_length = random.uniform(1.0, 5.0)\n",
    "        if current_time + voice_length > audio.duration:\n",
    "            voice_length = audio.duration - current_time\n",
    "            \n",
    "        segments.append((current_time, current_time + voice_length))\n",
    "        \n",
    "        # Random silence between segments\n",
    "        silence_length = random.uniform(0.2, 2.0)\n",
    "        current_time += voice_length + silence_length\n",
    "        \n",
    "        if current_time >= audio.duration:\n",
    "            break\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def auto_generate_segments(audio_id: UUID) -> List[UUID]:\n",
    "    \"\"\"\n",
    "    Automatically generate segments based on voice activity.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_id: UUID of the audio to segment\n",
    "    \n",
    "    Returns:\n",
    "    - List of UUIDs for the resulting AudioSegment objects\n",
    "    \"\"\"\n",
    "    # Detect voice activity\n",
    "    voice_segments = voice_activity_detection(audio_id)\n",
    "    \n",
    "    # Create segments\n",
    "    segment_ids = []\n",
    "    audio = load_audio_metadata(audio_id)\n",
    "    \n",
    "    for start, end in voice_segments:\n",
    "        segment = AudioSegment(\n",
    "            audio_id=audio.id,\n",
    "            start_time=start,\n",
    "            end_time=end\n",
    "        )\n",
    "        save_audio_metadata(segment)\n",
    "        segment_ids.append(segment.id)\n",
    "    \n",
    "    return segment_ids\n",
    "\n",
    "def batch_transcribe_segments(segment_ids: List[UUID]) -> Dict[UUID, str]:\n",
    "    \"\"\"\n",
    "    Transcribe multiple audio segments.\n",
    "    \n",
    "    Parameters:\n",
    "    - segment_ids: List of AudioSegment UUIDs to transcribe\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary mapping segment UUIDs to transcriptions\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for seg_id in segment_ids:\n",
    "        segment = load_audio_metadata(seg_id)\n",
    "        audio = load_audio_metadata(segment.audio_id)\n",
    "        \n",
    "        # Extract segment from audio\n",
    "        # In a real implementation, this would extract the actual audio segment\n",
    "        \n",
    "        # Transcribe the segment\n",
    "        transcription = f\"Transcription of segment {seg_id} from {segment.start_time:.2f}s to {segment.end_time:.2f}s\"\n",
    "        \n",
    "        results[seg_id] = transcription\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载播客录音：podcast_episode12.wav\n",
      "Applying noise reduction with strength 0.6 to podcast_episode12.wav\n",
      "已应用降噪处理\n",
      "Converting processed_7980250c-2b88-4809-a78d-a68419886ef2.wav from AudioFormat.WAV to AudioFormat.MP3\n",
      "已转换为MP3格式\n"
     ]
    }
   ],
   "source": [
    "def process_podcast_recording(file_path: str):\n",
    "    \"\"\"处理播客录音：降噪处理后转换为MP3格式\"\"\"\n",
    "    \n",
    "    # 创建原始音频\n",
    "    original_audio_id = create_audio_from_file(\n",
    "        file_path=file_path,\n",
    "        format=AudioFormat.WAV,\n",
    "        duration=45.5,\n",
    "        sample_rate=48000\n",
    "    )\n",
    "    print(f\"已加载播客录音：{file_path}\")\n",
    "    \n",
    "    # 降噪处理\n",
    "    cleaned_audio_id = noise_reduction(original_audio_id, strength=0.6)\n",
    "    print(\"已应用降噪处理\")\n",
    "    \n",
    "    # 转换为MP3格式（便于分享）\n",
    "    mp3_audio_id = change_audio_format(cleaned_audio_id, AudioFormat.MP3)\n",
    "    print(\"已转换为MP3格式\")\n",
    "    \n",
    "    return mp3_audio_id\n",
    "\n",
    "# 使用示例\n",
    "podcast_mp3_id = process_podcast_recording(\"podcast_episode12.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载采访录音：expert_interview.flac\n",
      "检测到语言：LanguageCode.JAPANESE\n",
      "将采访分为3个段落\n",
      "段落 1 [0.0s - 658.4s]: Transcription of segment 576315ca-1fd8-41a5-8095-a67aabac5320 from 0.00s to 658.44s\n",
      "段落 2 [658.4s - 898.9s]: Transcription of segment edcc542a-9815-4f54-b400-6f8c44081132 from 658.44s to 898.91s\n",
      "段落 3 [898.9s - 1250.0s]: Transcription of segment 1715178f-6a76-4c9e-b4b7-40e0499b77fd from 898.91s to 1250.00s\n"
     ]
    }
   ],
   "source": [
    "def transcribe_interview(interview_file: str):\n",
    "    \"\"\"处理采访录音：按静默部分分段并转录\"\"\"\n",
    "    \n",
    "    # 创建音频\n",
    "    interview_id = create_audio_from_file(\n",
    "        file_path=interview_file,\n",
    "        format=AudioFormat.FLAC,\n",
    "        duration=1250.0,  # 约20分钟\n",
    "        channels=2\n",
    "    )\n",
    "    print(f\"已加载采访录音：{interview_file}\")\n",
    "    \n",
    "    # 先检测语言\n",
    "    language = detect_language(interview_id)\n",
    "    print(f\"检测到语言：{language}\")\n",
    "    \n",
    "    # 按静默部分分段（可能是问答之间的停顿）\n",
    "    segments_ids = split_audio_by_silence(\n",
    "        interview_id, \n",
    "        min_silence_duration=0.7,\n",
    "        silence_threshold=-35\n",
    "    )\n",
    "    print(f\"将采访分为{len(segments_ids)}个段落\")\n",
    "    \n",
    "    # 批量转录所有段落\n",
    "    transcriptions = batch_transcribe_segments(segments_ids)\n",
    "    \n",
    "    # 打印转录结果\n",
    "    for i, (segment_id, text) in enumerate(transcriptions.items()):\n",
    "        segment = load_audio_metadata(segment_id)\n",
    "        print(f\"段落 {i+1} [{segment.start_time:.1f}s - {segment.end_time:.1f}s]: {text}\")\n",
    "    \n",
    "    return segments_ids, transcriptions\n",
    "\n",
    "# 使用示例\n",
    "segments, texts = transcribe_interview(\"expert_interview.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speech for text: 'It was the best of times, it was the worst of times, it was the age of wisdom...' using voice 'british_male' in LanguageCode.ENGLISH\n",
      "已生成有声书音频，长度约5.6秒\n",
      "Applying reverb effect with parameters {'room_size': 0.2, 'damping': 0.5, 'wet_level': 0.1, 'dry_level': 0.9} to tts_608038da-589a-4f93-a920-982985f6141c.wav\n",
      "Applying noise reduction with strength 0.7 to reverb_bccb2be8-30e9-4203-8188-02b95a18cdd2.wav\n",
      "Applying eq effect with parameters {'low': 1.2, 'mid': 1.0, 'high': 1.1} to processed_cc9e18c1-af8e-419b-b118-1c464836ebee.wav\n",
      "Applying compression effect with parameters {'threshold': -20, 'ratio': 4, 'attack': 5, 'release': 50} to eq_c3ecd01a-79ac-4c32-a99a-1aec3c854f38.wav\n",
      "已应用专业音频增强效果\n"
     ]
    }
   ],
   "source": [
    "def create_audiobook_chapter(chapter_text: str, voice: str = \"narrator\"):\n",
    "    \"\"\"创建有声书章节：文本转语音并增强音频效果\"\"\"\n",
    "    \n",
    "    # 文本转语音\n",
    "    raw_audio_id = text_to_speech(\n",
    "        text=chapter_text,\n",
    "        voice=voice,\n",
    "        language=LanguageCode.ENGLISH\n",
    "    )\n",
    "    print(f\"已生成有声书音频，长度约{len(chapter_text) * 0.07:.1f}秒\")\n",
    "    \n",
    "    # 应用音频效果，使其听起来更专业\n",
    "    # 1. 先添加轻微混响，增加空间感\n",
    "    reverb_audio_id = apply_effect(\n",
    "        raw_audio_id, \n",
    "        \"reverb\", \n",
    "        {\"room_size\": 0.2, \"damping\": 0.5, \"wet_level\": 0.1, \"dry_level\": 0.9}\n",
    "    )\n",
    "    \n",
    "    # 2. 应用压缩和均衡，使声音更饱满\n",
    "    enhanced_audio_id = enhance_audio(reverb_audio_id)\n",
    "    print(\"已应用专业音频增强效果\")\n",
    "    \n",
    "    return enhanced_audio_id\n",
    "\n",
    "# 使用示例\n",
    "chapter_text = \"It was the best of times, it was the worst of times, it was the age of wisdom...\"\n",
    "audiobook_id = create_audiobook_chapter(chapter_text, voice=\"british_male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载演讲：international_conference.wav\n",
      "已将演讲分为5个段落\n",
      "段落 1 [0.0s - 120.5s]: LanguageCode.GERMAN - Dies ist eine Beispieltranskription....\n",
      "段落 2 [120.5s - 350.2s]: LanguageCode.FRENCH - Ceci est une transcription exemple....\n",
      "段落 3 [350.2s - 560.0s]: LanguageCode.UNKNOWN - This is a sample transcription....\n",
      "段落 4 [560.0s - 720.8s]: LanguageCode.ENGLISH - This is a sample transcription....\n",
      "段落 5 [720.8s - 900.0s]: LanguageCode.UNKNOWN - This is a sample transcription....\n"
     ]
    }
   ],
   "source": [
    "def process_multilingual_speech(file_path: str):\n",
    "    \"\"\"处理多语言演讲：检测语言并按时间分段\"\"\"\n",
    "    \n",
    "    # 创建音频\n",
    "    speech_id = create_audio_from_file(\n",
    "        file_path=file_path,\n",
    "        format=AudioFormat.WAV,\n",
    "        duration=900.0,  # 15分钟\n",
    "        sample_rate=44100\n",
    "    )\n",
    "    print(f\"已加载演讲：{file_path}\")\n",
    "    \n",
    "    # 按时间点分段（假设我们已知演讲者在特定时间点切换语言）\n",
    "    time_points = [120.5, 350.2, 560.0, 720.8]  # 秒\n",
    "    segments_ids = split_audio_by_time(speech_id, time_points)\n",
    "    print(f\"已将演讲分为{len(segments_ids)}个段落\")\n",
    "    \n",
    "    # 检测每个段落的语言\n",
    "    results = []\n",
    "    for i, seg_id in enumerate(segments_ids):\n",
    "        segment = load_audio_metadata(seg_id)\n",
    "        segment_audio_id = create_audio_from_file(\n",
    "            f\"segment_{i}.wav\",\n",
    "            format=AudioFormat.WAV,\n",
    "            duration=segment.duration,\n",
    "            sample_rate=44100\n",
    "        )\n",
    "        \n",
    "        language = detect_language(segment_audio_id)\n",
    "        \n",
    "        # 转录该段\n",
    "        transcript = transcribe_audio(segment_audio_id, language)\n",
    "        \n",
    "        results.append({\n",
    "            \"segment\": i+1,\n",
    "            \"time_range\": f\"{segment.start_time:.1f}s - {segment.end_time:.1f}s\",\n",
    "            \"language\": language,\n",
    "            \"transcript\": transcript\n",
    "        })\n",
    "    \n",
    "    # 打印结果\n",
    "    for result in results:\n",
    "        print(f\"段落 {result['segment']} [{result['time_range']}]: {result['language']} - {result['transcript'][:50]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 使用示例\n",
    "speech_analysis = process_multilingual_speech(\"international_conference.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载通话录音：customer_service_call.mp3\n",
      "Applying noise reduction with strength 0.8 to customer_service_call.mp3\n",
      "已应用降噪处理\n",
      "检测到43个语音段落\n",
      "语音段落 1: 0.0s - 2.0s (持续2.0s)\n",
      "语音段落 2: 3.9s - 7.9s (持续4.0s)\n",
      "语音段落 3: 9.2s - 10.4s (持续1.2s)\n",
      "语音段落 4: 12.4s - 15.3s (持续2.9s)\n",
      "语音段落 5: 17.1s - 19.3s (持续2.2s)\n",
      "语音段落 6: 20.7s - 22.9s (持续2.2s)\n",
      "语音段落 7: 24.7s - 28.9s (持续4.3s)\n",
      "语音段落 8: 29.7s - 32.6s (持续2.9s)\n",
      "语音段落 9: 34.1s - 37.9s (持续3.8s)\n",
      "语音段落 10: 39.9s - 41.6s (持续1.7s)\n",
      "语音段落 11: 42.2s - 44.9s (持续2.7s)\n",
      "语音段落 12: 45.3s - 47.1s (持续1.8s)\n",
      "语音段落 13: 48.3s - 51.3s (持续3.0s)\n",
      "语音段落 14: 52.6s - 56.5s (持续3.9s)\n",
      "语音段落 15: 58.4s - 61.0s (持续2.6s)\n",
      "语音段落 16: 62.1s - 65.9s (持续3.8s)\n",
      "语音段落 17: 67.6s - 68.8s (持续1.1s)\n",
      "语音段落 18: 69.4s - 71.5s (持续2.1s)\n",
      "语音段落 19: 73.0s - 76.6s (持续3.6s)\n",
      "语音段落 20: 77.1s - 80.3s (持续3.2s)\n",
      "语音段落 21: 82.2s - 85.9s (持续3.7s)\n",
      "语音段落 22: 86.5s - 91.0s (持续4.4s)\n",
      "语音段落 23: 91.6s - 93.6s (持续2.1s)\n",
      "语音段落 24: 95.0s - 99.1s (持续4.2s)\n",
      "语音段落 25: 100.1s - 103.1s (持续3.0s)\n",
      "语音段落 26: 104.0s - 106.9s (持续2.9s)\n",
      "语音段落 27: 107.2s - 111.7s (持续4.5s)\n",
      "语音段落 28: 113.3s - 115.7s (持续2.4s)\n",
      "语音段落 29: 117.0s - 120.8s (持续3.8s)\n",
      "语音段落 30: 122.0s - 126.7s (持续4.7s)\n",
      "语音段落 31: 127.9s - 130.7s (持续2.9s)\n",
      "语音段落 32: 132.4s - 137.0s (持续4.6s)\n",
      "语音段落 33: 138.7s - 140.2s (持续1.5s)\n",
      "语音段落 34: 140.8s - 144.6s (持续3.8s)\n",
      "语音段落 35: 146.6s - 151.1s (持续4.6s)\n",
      "语音段落 36: 151.9s - 153.1s (持续1.2s)\n",
      "语音段落 37: 154.3s - 159.0s (持续4.7s)\n",
      "语音段落 38: 159.4s - 164.2s (持续4.8s)\n",
      "语音段落 39: 165.6s - 167.4s (持续1.9s)\n",
      "语音段落 40: 167.9s - 170.9s (持续3.0s)\n",
      "语音段落 41: 171.5s - 174.9s (持续3.4s)\n",
      "语音段落 42: 176.1s - 179.8s (持续3.7s)\n",
      "语音段落 43: 181.5s - 185.0s (持续3.5s)\n"
     ]
    }
   ],
   "source": [
    "def analyze_phone_call(call_recording: str):\n",
    "    \"\"\"分析电话通话：检测语音活动并降噪处理\"\"\"\n",
    "    \n",
    "    # 创建音频\n",
    "    call_id = create_audio_from_file(\n",
    "        file_path=call_recording,\n",
    "        format=AudioFormat.MP3,\n",
    "        duration=185.0,  # 约3分钟\n",
    "        sample_rate=8000,  # 电话音质\n",
    "        channels=1  # 单声道\n",
    "    )\n",
    "    print(f\"已加载通话录音：{call_recording}\")\n",
    "    \n",
    "    # 先降噪（电话通常有噪音）\n",
    "    cleaned_id = noise_reduction(call_id, strength=0.8)\n",
    "    print(\"已应用降噪处理\")\n",
    "    \n",
    "    # 检测语音活动（找出说话部分）\n",
    "    voice_segments = voice_activity_detection(cleaned_id)\n",
    "    print(f\"检测到{len(voice_segments)}个语音段落\")\n",
    "    \n",
    "    # 创建语音段落\n",
    "    segment_ids = []\n",
    "    for i, (start, end) in enumerate(voice_segments):\n",
    "        segment = AudioSegment(\n",
    "            audio_id=cleaned_id,\n",
    "            start_time=start,\n",
    "            end_time=end\n",
    "        )\n",
    "        save_audio_metadata(segment)\n",
    "        segment_ids.append(segment.id)\n",
    "        print(f\"语音段落 {i+1}: {start:.1f}s - {end:.1f}s (持续{end-start:.1f}s)\")\n",
    "    \n",
    "    # 转录所有语音段落\n",
    "    transcriptions = batch_transcribe_segments(segment_ids)\n",
    "    \n",
    "    return cleaned_id, segment_ids, transcriptions\n",
    "\n",
    "# 使用示例\n",
    "clean_call_id, voice_segments, texts = analyze_phone_call(\"customer_service_call.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载4个音轨\n",
      "Merging 4 segments with 3.0s crossfade\n",
      "已合并所有音轨，使用3秒交叉淡入淡出\n",
      "Converting merged_cf230c21-cedb-4c0c-be15-abd26cfcf56c.mp3 from AudioFormat.MP3 to AudioFormat.FLAC\n",
      "已转换为flac格式\n",
      "Adjusting audio properties: sample_rate=96000, bit_depth=24, channels=None\n",
      "已调整为高质量音频属性\n"
     ]
    }
   ],
   "source": [
    "def create_music_compilation(track_files: List[str], output_format: AudioFormat = AudioFormat.FLAC):\n",
    "    \"\"\"创建音乐合辑：合并多个音频并转换格式\"\"\"\n",
    "    \n",
    "    # 加载所有音轨\n",
    "    track_ids = []\n",
    "    for file_path in track_files:\n",
    "        # 确定文件格式\n",
    "        extension = Path(file_path).suffix.lower()[1:]\n",
    "        format_value = None\n",
    "        for fmt in AudioFormat:\n",
    "            if fmt.value == extension:\n",
    "                format_value = fmt\n",
    "                break\n",
    "        if not format_value:\n",
    "            format_value = AudioFormat.WAV  # 默认\n",
    "            \n",
    "        # 创建音频\n",
    "        track_id = create_audio_from_file(\n",
    "            file_path=file_path,\n",
    "            format=format_value,\n",
    "            duration=random.uniform(180, 300)  # 3-5分钟\n",
    "        )\n",
    "        track_ids.append(track_id)\n",
    "    \n",
    "    print(f\"已加载{len(track_ids)}个音轨\")\n",
    "    \n",
    "    # 创建每个音轨的片段（完整轨道）\n",
    "    segment_ids = []\n",
    "    for track_id in track_ids:\n",
    "        track = load_audio_metadata(track_id)\n",
    "        segment = AudioSegment(\n",
    "            audio_id=track_id,\n",
    "            start_time=0,\n",
    "            end_time=track.duration\n",
    "        )\n",
    "        save_audio_metadata(segment)\n",
    "        segment_ids.append(segment.id)\n",
    "    \n",
    "    # 合并所有片段，使用交叉淡入淡出\n",
    "    merged_id = merge_audio_segments(segment_ids, crossfade=3.0)\n",
    "    print(\"已合并所有音轨，使用3秒交叉淡入淡出\")\n",
    "    \n",
    "    # 转换为目标格式\n",
    "    final_id = change_audio_format(merged_id, output_format)\n",
    "    print(f\"已转换为{output_format.value}格式\")\n",
    "    \n",
    "    # 调整音频属性（高质量输出）\n",
    "    adjusted_id = adjust_audio_properties(\n",
    "        final_id,\n",
    "        sample_rate=96000,\n",
    "        bit_depth=24\n",
    "    )\n",
    "    print(\"已调整为高质量音频属性\")\n",
    "    \n",
    "    return adjusted_id\n",
    "\n",
    "# 使用示例\n",
    "track_files = [\"track1.mp3\", \"track2.wav\", \"track3.mp3\", \"track4.flac\"]\n",
    "compilation_id = create_music_compilation(track_files, AudioFormat.FLAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
